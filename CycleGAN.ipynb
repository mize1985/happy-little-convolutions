{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import (Activation, Concatenate, Conv2D,\n",
    "                                     Conv2DTranspose, Input, LeakyReLU)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 200\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This block loads the Monet2Photo dataset. If you want to run the model on that instead, or at first, skip the other data loading blocks, which will overwrite all of these datasets except for the photographic landscapes (trainB/train_y)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data, metadata = tfds.load('cycle_gan/monet2photo', with_info=True, as_supervised=True)\n",
    "\n",
    "train_x, train_y, test_x, test_y = data['trainA'], data['trainB'], data['testA'], data['testB']\n",
    "\n",
    "# Normalize images to [-1, 1] and reshape\n",
    "def preprocess_image(image, _):\n",
    "    return tf.reshape(tf.cast(tf.image.resize(image, (int(IMG_HEIGHT),\n",
    "        int(IMG_WIDTH)),method=tf.image.ResizeMethod.BICUBIC),\n",
    "        tf.float32) / 127.5 - 1, (1, IMG_HEIGHT, IMG_WIDTH, channels))\n",
    "\n",
    "# Map the normalization onto the dataset\n",
    "train_x = train_x.map(preprocess_image)\n",
    "train_y = train_y.map(preprocess_image)\n",
    "test_x = test_x.map(preprocess_image)\n",
    "test_y = test_y.map(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fname):\n",
    "    \n",
    "    image = tf.io.read_file(fname)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, height, width):\n",
    "    \n",
    "    image = tf.image.resize(image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.BICUBIC)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    \n",
    "    cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    \n",
    "    image = (image / 127.5) - 1\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def random_jitter(image):\n",
    "    \n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = resize(image, 286, 286)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # random mirroring\n",
    "        image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(fname):\n",
    "    \n",
    "    image = load(fname)\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(fname):\n",
    "    \n",
    "    image = load(fname)\n",
    "    image = resize(image,IMG_HEIGHT, IMG_WIDTH)\n",
    "    image = normalize(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input file paths\n",
    "\n",
    "_place your files in directories with these names, or update the doce to match your directories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tf.data.Dataset.list_files('bob_ross_train/*.jpg', shuffle=True)\n",
    "train_x = train_x.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_x = train_x.shuffle(BUFFER_SIZE)\n",
    "train_x = train_x.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "test_x = tf.data.Dataset.list_files('bob_ross_test/*.jpg', shuffle=True)\n",
    "test_x = test_x.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_x = test_x.shuffle(BUFFER_SIZE)\n",
    "test_x = test_x.batch(BATCH_SIZE)\n",
    "\n",
    "test_y = tf.data.Dataset.list_files('landscape_photo_test/*.jpg', shuffle=True)\n",
    "test_y = test_y.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_y = test_y.shuffle(BUFFER_SIZE)\n",
    "test_y = test_y.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "epochs = 500\n",
    "\n",
    "LAMBDA = 10\n",
    "\n",
    "img_rows, img_cols, channels = 256, 256, 3\n",
    "weight_initializer = RandomNormal(stddev=0.02)\n",
    "\n",
    "\n",
    "gen_g_optimizer = gen_f_optimizer = Adam(lr=0.0001, beta_1=0.5)\n",
    "dis_x_optimizer = dis_y_optimizer = Adam(lr=0.0001, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Ck denotes a 4 × 4 Convolution-InstanceNorm-LeakyReLU layer with k filters and stride 2\n",
    "def Ck(input, k, use_instancenorm=True):\n",
    "    block = Conv2D(k, (4, 4), strides=2, padding='same', kernel_initializer=weight_initializer)(input)\n",
    "    if use_instancenorm:\n",
    "        block = InstanceNormalization(axis=-1)(block)\n",
    "    block = LeakyReLU(0.2)(block)\n",
    "\n",
    "    return block\n",
    "\n",
    "# C64, C128, C256, C512\n",
    "def discriminator():\n",
    "    dis_input = Input(shape=(img_rows, img_cols, channels))\n",
    "\n",
    "    d = Ck(dis_input, 64, False)\n",
    "    d = Ck(d, 128)\n",
    "    d = Ck(d, 256)\n",
    "    d = Ck(d, 512)\n",
    "\n",
    "    d = Conv2D(1, (4, 4), padding='same', kernel_initializer=weight_initializer)(d)\n",
    "\n",
    "    return Model(dis_input, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"dk denotes a 3×3 Convolution-InstanceNorm-ReLU with k filters and stride 2\"\n",
    "def dk(k, use_instancenorm=True):\n",
    "    block = Sequential()\n",
    "    block.add(Conv2D(k, (3, 3), strides=2, padding='same', kernel_initializer=weight_initializer))\n",
    "    if use_instancenorm:\n",
    "        block.add(InstanceNormalization(axis=-1))\n",
    "    block.add(Activation('relu'))\n",
    "\n",
    "    return block\n",
    "\n",
    "# \"uk denotes a 3×3 fractional-strided-ConvolutionInstanceNorm-ReLU layer with k filters and stride ½\"\n",
    "def uk(k):\n",
    "    block = Sequential()\n",
    "    block.add(Conv2DTranspose(k, (3, 3), strides=2, padding='same', kernel_initializer=weight_initializer))\n",
    "    block.add(InstanceNormalization(axis=-1))\n",
    "    block.add(Activation('relu'))\n",
    "\n",
    "    return block\n",
    "\n",
    "def generator():\n",
    "    gen_input = Input(shape=(img_rows, img_cols, channels))\n",
    "    \n",
    "    # Layers for the encoder part of the model\n",
    "    encoder_layers = [\n",
    "        dk(64, False),\n",
    "        dk(128),\n",
    "        dk(256),\n",
    "        dk(512),\n",
    "        dk(512),\n",
    "        dk(512),\n",
    "        dk(512),\n",
    "        dk(512)\n",
    "    ]\n",
    "\n",
    "    # Layers for the decoder part of the model\n",
    "\n",
    "    decoder_layers = [\n",
    "        uk(512),\n",
    "        uk(512),\n",
    "        uk(512),\n",
    "        uk(512),\n",
    "        uk(256),\n",
    "        uk(128),\n",
    "        uk(64)\n",
    "    ]\n",
    "\n",
    "    gen = gen_input\n",
    "\n",
    "        # Add all the encoder layers, and keep track of them for skip connections\n",
    "    skips = []\n",
    "    for layer in encoder_layers:\n",
    "        gen = layer(gen)\n",
    "        skips.append(gen)\n",
    "    \n",
    "    skips = skips[::-1][1:] # Reverse for looping and get rid of the layer that directly connects to decoder\n",
    "\n",
    "    # Add all the decoder layers and skip connections\n",
    "    for skip_layer, layer in zip(skips, decoder_layers):\n",
    "        gen = layer(gen)\n",
    "        gen = Concatenate()([gen, skip_layer])\n",
    "\n",
    "    \n",
    "    # Final layer\n",
    "    gen = Conv2DTranspose(channels, (3, 3), strides=2, padding='same', kernel_initializer=weight_initializer, activation='tanh')(gen)\n",
    "    \n",
    "    # Compose model\n",
    "    return Model(gen_input, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "generator_g = generator()\n",
    "generator_f = generator()\n",
    "\n",
    "discriminator_x = discriminator()\n",
    "discriminator_y = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "loss = BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Measures how close to one real images are rated, and how close to zero fake images are rated\n",
    "def discriminator_loss(real, generated):\n",
    "    # Multiplied by 0.5 so that it will train at half-speed\n",
    "    return (loss(tf.ones_like(real), real) + loss(tf.zeros_like(generated), generated)) * 0.5\n",
    "\n",
    "# Measures how real the discriminator believes the fake image is\n",
    "def gen_loss(validity):\n",
    "    return loss(tf.ones_like(validity), validity)\n",
    "\n",
    "# Measures similarity of two images.  Used for cycle and identity loss\n",
    "def image_similarity(image1, image2):\n",
    "    return tf.reduce_mean(tf.abs(image1 - image2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def step(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Setup Dy loss\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        gen_g_validity = discriminator_y(fake_y, training=True)\n",
    "        dis_y_loss = discriminator_loss(discriminator_y(real_y, training=True), gen_g_validity)\n",
    "\n",
    "        with tape.stop_recording():\n",
    "            discriminator_y_gradients = tape.gradient(dis_y_loss, discriminator_y.trainable_variables)\n",
    "            dis_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n",
    "\n",
    "        # Setup Dx loss\n",
    "        fake_x = generator_f(real_y, training=True)\n",
    "        gen_f_validity = discriminator_x(fake_x, training=True)\n",
    "        dis_x_loss = discriminator_loss(discriminator_x(real_x, training=True), gen_f_validity)\n",
    "\n",
    "        with tape.stop_recording():\n",
    "            discriminator_x_gradients = tape.gradient(dis_x_loss, discriminator_x.trainable_variables)\n",
    "            dis_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
    "\n",
    "        # Setup adversarial losses\n",
    "        gen_g_adv_loss = gen_loss(gen_g_validity)\n",
    "        gen_f_adv_loss = gen_loss(gen_f_validity)\n",
    "\n",
    "        # Setup cycle losses\n",
    "        cyc_x = generator_f(fake_y, training=True)\n",
    "        cyc_x_loss = image_similarity(real_x, cyc_x)\n",
    "\n",
    "        cyc_y = generator_g(fake_x, training=True)\n",
    "        cyc_y_loss =  image_similarity(real_y, cyc_y)\n",
    "\n",
    "        # Setup identity losses\n",
    "        id_x = generator_f(real_x, training=True)\n",
    "        id_x_loss = image_similarity(real_x, id_x)\n",
    "\n",
    "        id_y = generator_g(real_y, training=True)\n",
    "        id_y_loss = image_similarity(real_y, id_y)\n",
    "\n",
    "        # Finalize generator losses and calc gradients\n",
    "        gen_g_loss = gen_g_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_y_loss * 0.5*LAMBDA\n",
    "        gen_f_loss = gen_f_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_x_loss * 0.5*LAMBDA\n",
    "\n",
    "        with tape.stop_recording():\n",
    "            generator_g_gradients = tape.gradient(gen_g_loss, generator_g.trainable_variables)\n",
    "            gen_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
    "\n",
    "            generator_f_gradients = tape.gradient(gen_f_loss, generator_f.trainable_variables)\n",
    "            gen_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images():\n",
    "    # Sample images\n",
    "    x = next(iter(test_x.shuffle(1000))).numpy()\n",
    "    y = next(iter(test_y.shuffle(1000))).numpy()\n",
    "    \n",
    "    # Get predictions for those images\n",
    "    y_hat = generator_g.predict(x.reshape((1, img_rows, img_cols, channels)))\n",
    "    x_hat = generator_f.predict(y.reshape((1, img_rows, img_cols, channels)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    images = [x[0], y_hat[0], y[0], x_hat[0]]\n",
    "\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(images[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Use this function to test the model on your specific test images_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(filepath):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    photo = load_image_test(filepath).numpy()\n",
    "    # Get a prediction for this image\n",
    "    painting = generator_f.predict(photo.reshape((1, img_rows, img_cols, channels)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    images=[photo,painting[0]]\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.imshow(images[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_image('cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/small\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           gen_g_optimizer=gen_g_optimizer,\n",
    "                           gen_f_optimizer=gen_f_optimizer,\n",
    "                           dis_x_optimizer=dis_x_optimizer,\n",
    "                           dis_y_optimizer=dis_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "\n",
    "#if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "# Manually loop through epochs\n",
    "for epoch in range(700):\n",
    "    display.clear_output(wait=True)\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    start = time.time()\n",
    "    generate_images()\n",
    "    \n",
    "\n",
    "    # Each batch\n",
    "    for k, (real_x, real_y) in enumerate(tf.data.Dataset.zip((train_x, train_y))):\n",
    "        if k % 100 == 0: print(k)\n",
    "        # Train step\n",
    "        step(tf.reshape(real_x, (1, img_rows, img_cols, channels)), tf.reshape(real_y, (1, img_rows, img_cols, channels)))\n",
    "    \n",
    "    # View progresshttps://www.alt-codes.net/arrow_alt_codes.php\n",
    "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                        time.time()-start))\n",
    "    if epoch % 10 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
